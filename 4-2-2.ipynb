{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa2eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "訓練データと正解ラベル\n",
    "'''\n",
    "train = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1],])\n",
    "label = np.array([[0],\n",
    "                  [1],\n",
    "                  [1],\n",
    "                  [0],])\n",
    "\n",
    "'''\n",
    "モデルの定義\n",
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "class MLP(tf.keras.Model):\n",
    "    '''\n",
    "    多層パーセプトロン\n",
    "    Attributes:\n",
    "        l1(Dense): 隠れ層\n",
    "        l2(Dense): 出力層\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        '''\n",
    "        モデルの初期化を行う\n",
    "        Parameters:\n",
    "            input_dim(int): 出力する1データあたりの値の形状\n",
    "            hidden_dim(int): 隠れ層のニューロン数\n",
    "            outpu_dim(int): 出力層のニューロン数\n",
    "        '''\n",
    "        super(MLP, self).__init__() #スーパークラスの__init__()を実行\n",
    "        \n",
    "        #隠れ層\n",
    "        self.l1 = tf.keras.layers.Dense(\n",
    "            units = hidden_dim, #ニューロンのサイズ(数)\n",
    "            input_dim = input_dim, #入力データの形状\n",
    "            activation = 'sigmoid') #活性化関数=sigmoid\n",
    "        \n",
    "        #出力層\n",
    "        self.l2 = tf.keras.layers.Dense(\n",
    "            units = output_dim,\n",
    "            activation = 'sigmoid')\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x, training = None):\n",
    "            '''モデルのインスタンスからコールバックされる関数\n",
    "            \n",
    "            MLPの順伝播処理を行う\n",
    "            \n",
    "            Parameters:\n",
    "                x(ndarray(float32)): 訓練データ、or 検証データ\n",
    "                training(bool): 訓練True, 検証False\n",
    "                \n",
    "            Returns(float32): 出力層からの出力値\n",
    "            '''\n",
    "            h = self.l1(x) #隠れ層の出力\n",
    "            y = self.l2(h) #出力層の出力\n",
    "            return y\n",
    "\n",
    "#入力層2ニューロン、隠れ層2ニューロン、出力層1ニューロンのモデルを生成\n",
    "model = MLP(2, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea89188",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. 損失関数とオプティマイザーの生成\n",
    "'''\n",
    "#バイナリ用のクロスエントロピー誤差のオブジェクトを生成\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "#勾配降下アルゴリズムを使用するオプティマイザーを生成\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.5)\n",
    "#学習速度を上げる＝パラメータの更新値を大きくする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec815d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "4. 勾配降下アルゴリズムによるパラメータの更新処理\n",
    "'''\n",
    "@tf.function\n",
    "def train_step(x, t):\n",
    "        '''バックプロパゲーションによるパラメータ更新を行う\n",
    "        \n",
    "        Parameters: x(ndarray(float32)): 訓練データ\n",
    "                              t(ndarray(float32)): 正解ラベル\n",
    "        \n",
    "        Returns: MLPの出力と正解ラベルのクロスエントロピー誤差\n",
    "        '''\n",
    "        \n",
    "        #自動微分による購買計算のための操作を記録するブロおく\n",
    "        with tf.GradientTape() as tape:\n",
    "                predictions = model(x) #モデルに入力して順伝播の出力値を取得\n",
    "                pred_loss = loss_fn(t, predictions) #出力値と正解ラベルの誤差を取得\n",
    "                \n",
    "        #tapeに記録された操作を使用して誤差の勾配を計算\n",
    "        gradients = tape.gradient(\n",
    "                pred_loss, #現在の誤差\n",
    "                model.trainable_variables) #更新可能なバイアス、重みのリストを取得\n",
    "        \n",
    "        #勾配降下法の更新式を適用してバイアス、重みを更新\n",
    "        optimizer.apply_gradients(\n",
    "                zip(gradients, #取得済みの勾配\n",
    "                       model.trainable_variables #更新可能なバイアス、重みのリスト\n",
    "                       ))\n",
    "        \n",
    "        return pred_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a17bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:09:13.008874: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-30 17:09:13.011388: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000: 0.369698703289032\n",
      "2000: 0.3547428250312805\n",
      "3000: 0.3513994514942169\n",
      "4000: 0.3499673902988434\n",
      "Model: \"mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "モデルを使用して学習する\n",
    "'''\n",
    "#エポック数\n",
    "epochs = 4000\n",
    "\n",
    "#学習を行う\n",
    "for epoch in range(epochs):\n",
    "        #1epochごとの損失を保持する変数\n",
    "        epoch_loss = 0.\n",
    "        \n",
    "        #データをモデルに入力し、バイアス、重みを更新して誤差を取得\n",
    "        loss = train_step(train, label)\n",
    "        epoch_loss = epoch_loss + loss.numpy()\n",
    "        \n",
    "        #1000epochごとに結果を出力\n",
    "        if (epoch + 1) % 1000 == 0:\n",
    "                print(f'{epoch + 1}: {epoch_loss}')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8d68bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.00350738]\n",
      " [0.4986658 ]\n",
      " [0.9960474 ]\n",
      " [0.5017097 ]], shape=(4, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]], shape=(4, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "6. モデルを評価する\n",
    "'''\n",
    "#学習済みのMLPの出力\n",
    "print(model(train))\n",
    "\n",
    "#学習した重み・バイアスを使って、XORゲートの出力を表示\n",
    "#MLPの出力が0.5以上であれば1、そうでなければ0を返す\n",
    "print(tf.cast(\n",
    "            (model(train) >= 0.5), tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08fb1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "#XORゲートの入力値、0と1の組み合わせの行列(4*2)\n",
    "X = np.array([\n",
    "    [0, 0], [0, 1], [1, 0], [1, 1]\n",
    "])\n",
    "\n",
    "#XORゲートの出力、正解ラベルの行列(4*1)、0はFalse、1はTrue\n",
    "T = np.array([\n",
    "    [0], [1], [1], [0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e021f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
